{
 "cells": [
  {
   "source": [
    "# RIIID - SAINT Model (Encoder only) Inference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-01T10:44:47.173728Z",
     "iopub.status.busy": "2021-01-01T10:44:47.173010Z",
     "iopub.status.idle": "2021-01-01T10:44:49.767586Z",
     "shell.execute_reply": "2021-01-01T10:44:49.766819Z"
    },
    "papermill": {
     "duration": 2.612471,
     "end_time": "2021-01-01T10:44:49.767700",
     "exception": false,
     "start_time": "2021-01-01T10:44:47.155229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import riiideducation\n",
    "import math\n",
    "import torch\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import deque, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T10:44:49.794867Z",
     "iopub.status.busy": "2021-01-01T10:44:49.794081Z",
     "iopub.status.idle": "2021-01-01T10:44:49.797140Z",
     "shell.execute_reply": "2021-01-01T10:44:49.796514Z"
    },
    "papermill": {
     "duration": 0.017176,
     "end_time": "2021-01-01T10:44:49.797234",
     "exception": false,
     "start_time": "2021-01-01T10:44:49.780058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = riiideducation.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T10:44:49.821827Z",
     "iopub.status.busy": "2021-01-01T10:44:49.821001Z",
     "iopub.status.idle": "2021-01-01T10:44:49.824080Z",
     "shell.execute_reply": "2021-01-01T10:44:49.823571Z"
    },
    "papermill": {
     "duration": 0.017084,
     "end_time": "2021-01-01T10:44:49.824184",
     "exception": false,
     "start_time": "2021-01-01T10:44:49.807100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AMOUNT = 100\n",
    "PAD = 0\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T10:44:49.852801Z",
     "iopub.status.busy": "2021-01-01T10:44:49.852088Z",
     "iopub.status.idle": "2021-01-01T10:44:49.879170Z",
     "shell.execute_reply": "2021-01-01T10:44:49.878592Z"
    },
    "papermill": {
     "duration": 0.044847,
     "end_time": "2021-01-01T10:44:49.879279",
     "exception": false,
     "start_time": "2021-01-01T10:44:49.834432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "QUESTIONS_PATH = '../input/riiid-test-answer-prediction/questions.csv'\n",
    "df_questions = pd.read_csv(QUESTIONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T10:44:49.909267Z",
     "iopub.status.busy": "2021-01-01T10:44:49.908611Z",
     "iopub.status.idle": "2021-01-01T10:44:49.919547Z",
     "shell.execute_reply": "2021-01-01T10:44:49.918861Z"
    },
    "papermill": {
     "duration": 0.029491,
     "end_time": "2021-01-01T10:44:49.919649",
     "exception": false,
     "start_time": "2021-01-01T10:44:49.890158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "part_ids_map = dict(zip(df_questions.question_id, df_questions.part))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010704,
     "end_time": "2021-01-01T10:44:49.940934",
     "exception": false,
     "start_time": "2021-01-01T10:44:49.930230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T10:44:50.054829Z",
     "iopub.status.busy": "2021-01-01T10:44:50.049437Z",
     "iopub.status.idle": "2021-01-01T10:44:50.057139Z",
     "shell.execute_reply": "2021-01-01T10:44:50.057633Z"
    },
    "papermill": {
     "duration": 0.106576,
     "end_time": "2021-01-01T10:44:50.057776",
     "exception": false,
     "start_time": "2021-01-01T10:44:49.951200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataset_transform(dataset):\n",
    "  final_dataset = {}\n",
    "  user_id_to_idx = {}\n",
    "  grp = dataset.groupby('user_id').tail(AMOUNT)\n",
    "  \n",
    "  for idx, row in tqdm(grp.groupby(\"user_id\").agg({\"content_id\":list, \n",
    "                \"answered_correctly\":list, \n",
    "                \"task_container_id\":list, \n",
    "                \"part_id\":list, \n",
    "                \"prior_question_elapsed_time\":list}).reset_index().iterrows()):\n",
    "\n",
    "    # pad the required rows to have AMOUNT values\n",
    "    if (len(row['content_id']) >= AMOUNT):\n",
    "      final_dataset[idx] = {\n",
    "            \"user_id\": row[\"user_id\"],\n",
    "            \"content_id\" : deque(row[\"content_id\"], maxlen=AMOUNT),\n",
    "            \"answered_correctly\" : deque(row[\"answered_correctly\"], maxlen=AMOUNT),\n",
    "            \"task_container_id\" : deque(row[\"task_container_id\"], maxlen=AMOUNT),\n",
    "            \"prior_question_elapsed_time\" : deque(row[\"prior_question_elapsed_time\"], maxlen=AMOUNT),\n",
    "            \"part_id\": deque(row[\"part_id\"], maxlen=AMOUNT),\n",
    "            \"padded\" : deque([False]*100, maxlen=AMOUNT)\n",
    "        }\n",
    "    else: # need to pad\n",
    "        final_dataset[idx] = {\n",
    "            \"user_id\": row[\"user_id\"],\n",
    "            \"content_id\" : deque(row[\"content_id\"] + [PAD]*(AMOUNT-len(row[\"content_id\"])), maxlen=AMOUNT),\n",
    "            \"answered_correctly\" : deque(row[\"answered_correctly\"] + [PAD]*(AMOUNT-len(row[\"content_id\"])), maxlen=AMOUNT),\n",
    "            \"task_container_id\" : deque(row[\"task_container_id\"] + [PAD]*(AMOUNT-len(row[\"content_id\"])), maxlen=AMOUNT),\n",
    "            \"prior_question_elapsed_time\" : deque(row[\"prior_question_elapsed_time\"] + [PAD]*(AMOUNT-len(row[\"content_id\"])), maxlen=AMOUNT),\n",
    "            \"part_id\": deque(row[\"part_id\"] + [PAD]*(AMOUNT-len(row[\"content_id\"])), maxlen=AMOUNT),\n",
    "            \"padded\" : deque([False]*len(row[\"content_id\"]) + [True]*(AMOUNT-len(row[\"content_id\"])), maxlen=AMOUNT)\n",
    "        }\n",
    "\n",
    "    user_id_to_idx[row['user_id']] = idx\n",
    "  # FIXME new users? \n",
    "  return final_dataset, user_id_to_idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T10:44:50.085334Z",
     "iopub.status.busy": "2021-01-01T10:44:50.084718Z",
     "iopub.status.idle": "2021-01-01T10:45:22.649076Z",
     "shell.execute_reply": "2021-01-01T10:45:22.647792Z"
    },
    "papermill": {
     "duration": 32.579733,
     "end_time": "2021-01-01T10:45:22.649228",
     "exception": false,
     "start_time": "2021-01-01T10:44:50.069495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../input/saint-model/user_prepared_dataframe.pickle', 'rb') as f:\n",
    "    user_data = pickle.load(f)\n",
    "\n",
    "with open('../input/saint-model/user_index_dataframe.pickle', 'rb') as f:\n",
    "    user_idx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T10:45:22.701709Z",
     "iopub.status.busy": "2021-01-01T10:45:22.699785Z",
     "iopub.status.idle": "2021-01-01T10:45:22.702442Z",
     "shell.execute_reply": "2021-01-01T10:45:22.702919Z"
    },
    "papermill": {
     "duration": 0.04275,
     "end_time": "2021-01-01T10:45:22.703039",
     "exception": false,
     "start_time": "2021-01-01T10:45:22.660289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Riiid(torch.utils.data.Dataset):\n",
    "    \n",
    "    def generate(idx):\n",
    "        return {\n",
    "            \"user_id\": idx,\n",
    "            \"content_id\" : deque([PAD]*AMOUNT, maxlen=AMOUNT),\n",
    "            \"answered_correctly\" : deque([PAD]*AMOUNT, maxlen=AMOUNT),\n",
    "            \"task_container_id\" : deque([PAD]*AMOUNT, maxlen=AMOUNT),\n",
    "            \"prior_question_elapsed_time\" : deque([PAD]*AMOUNT, maxlen=AMOUNT),\n",
    "            \"part_id\": deque([PAD]*AMOUNT, maxlen=AMOUNT),\n",
    "            \"padded\" : deque([True]*AMOUNT, maxlen=AMOUNT),\n",
    "        }\n",
    "    \n",
    "    def __init__(self, d, idxs):\n",
    "        self.d = d\n",
    "        self.idxs = idxs \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.d)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx not in self.idxs:\n",
    "                self.idxs[idx] = max(self.d.keys()) + 1\n",
    "                self.d[self.idxs[idx]] = Riiid.generate(idx)\n",
    "        idx = self.idxs[idx]\n",
    "        return idx, self.d[idx][\"content_id\"], self.d[idx][\"task_container_id\"], \\\n",
    "    self.d[idx][\"part_id\"], self.d[idx][\"prior_question_elapsed_time\"], self.d[idx][\"padded\"], \\\n",
    "    self.d[idx][\"answered_correctly\"]\n",
    "            \n",
    "    \n",
    "    def update(self, df):\n",
    "        user_id = np.array(df['user_id'])\n",
    "        df_content_id = np.array(df['content_id'])\n",
    "        df_task_container_id = np.array(df['task_container_id'])\n",
    "        df_prior_question_elapsed_time = np.array(df['prior_question_elapsed_time'])\n",
    "        df_part_id = np.array(df['part_id'])\n",
    "        size = len(user_id)\n",
    "\n",
    "        for i in range(size):\n",
    "          _, content_id, task_container_id, part_id, prior_question_elapsed_time, padded, labels = self[user_id[i]]\n",
    "          content_id.popleft()\n",
    "          task_container_id.popleft()\n",
    "          prior_question_elapsed_time.popleft()\n",
    "          part_id.popleft()\n",
    "          padded.popleft()\n",
    "          \n",
    "          content_id.append(df_content_id[i])\n",
    "          task_container_id.append(df_task_container_id[i])\n",
    "          prior_question_elapsed_time.append(df_prior_question_elapsed_time[i])\n",
    "          part_id.append(df_part_id[i])\n",
    "          padded.append(False)\n",
    "            \n",
    "\n",
    "def collate_fn(batch):\n",
    "    _, content_id, task_id, part_id, prior_question_elapsed_time, padded, labels = zip(*batch)\n",
    "    content_id = torch.Tensor(content_id).long()\n",
    "    task_id = torch.Tensor(task_id).long()\n",
    "    part_id = torch.Tensor(part_id).long()\n",
    "    prior_question_elapsed_time = torch.Tensor(prior_question_elapsed_time).long()\n",
    "    padded = torch.Tensor(padded).bool()\n",
    "    labels = torch.Tensor(labels)\n",
    "    return content_id, task_id, part_id, prior_question_elapsed_time, padded, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010843,
     "end_time": "2021-01-01T10:45:22.724671",
     "exception": false,
     "start_time": "2021-01-01T10:45:22.713828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SAINT  Model (Encoder only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T10:45:22.769933Z",
     "iopub.status.busy": "2021-01-01T10:45:22.768632Z",
     "iopub.status.idle": "2021-01-01T10:45:22.771432Z",
     "shell.execute_reply": "2021-01-01T10:45:22.771855Z"
    },
    "papermill": {
     "duration": 0.036498,
     "end_time": "2021-01-01T10:45:22.771984",
     "exception": false,
     "start_time": "2021-01-01T10:45:22.735486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SAINT(nn.Module):\n",
    "  def __init__(self, ninp=32, nhead=2, nhid=64, nlayers=2, dropout=0.1):\n",
    "    super(SAINT, self).__init__()\n",
    "    # Note: there is no positional encoding for SAINT\n",
    "    self.src_mask = None\n",
    "    encoder_layers = TransformerEncoderLayer(d_model=ninp, nhead=nhead, dim_feedforward=nhid, dropout=dropout, activation='relu')\n",
    "    self.transformer_encoder = TransformerEncoder(encoder_layer=encoder_layers, num_layers=nlayers)\n",
    "    self.exercise_embeddings = nn.Embedding(num_embeddings=13523, embedding_dim=ninp) # exercise_id\n",
    "    self.pos_embedding = nn.Embedding(ninp, ninp) # positional embeddings\n",
    "    self.part_embeddings = nn.Embedding(num_embeddings=7+1, embedding_dim=ninp) # part_id_embeddings\n",
    "    self.prior_question_elapsed_time = nn.Embedding(num_embeddings=301, embedding_dim=ninp) # prior_question_elapsed_time\n",
    "    self.device = \"cpu\" if not torch.cuda.is_available() else torch.device('cuda')\n",
    "    self.ninp = ninp\n",
    "    self.decoder = nn.Linear(ninp, 2)\n",
    "    self.init_weights()\n",
    "  \n",
    "  def init_weights(self):\n",
    "    initrange = 0.1\n",
    "    # init embeddings\n",
    "    # FIXME should be Xavier uniform acording to paper\n",
    "    self.exercise_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "    self.part_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "    self.prior_question_elapsed_time.weight.data.uniform_(-initrange, initrange)\n",
    "    self.decoder.bias.data.zero_()\n",
    "    self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "  def generate_square_subsequent_mask(self, sz):\n",
    "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "  def forward(self, content_id, part_id, prior_question_elapsed_time=None, mask_src=None):\n",
    "    # Generate embeddings according to paper\n",
    "    content_id = content_id.to(self.device)\n",
    "    part_id = part_id.to(self.device)\n",
    "    prior_question_elapsed_time = prior_question_elapsed_time.to(self.device)\n",
    "    mask_src = mask_src.to(self.device)\n",
    "\n",
    "    embedded_src = self.exercise_embeddings(content_id) + \\\n",
    "        self.pos_embedding(torch.arange(0, content_id.shape[1]).to(self.device).unsqueeze(0).repeat(content_id.shape[0], 1)) + \\\n",
    "        self.part_embeddings(part_id) + self.prior_question_elapsed_time(prior_question_elapsed_time) # (N, S, E)\n",
    "    embedded_src = embedded_src.transpose(0, 1) # (S, N, E)\n",
    "    \n",
    "    # Standard transformer\n",
    "    _src = embedded_src * np.sqrt(self.ninp)\n",
    "    \n",
    "    output = self.transformer_encoder(src=_src, src_key_padding_mask=mask_src)\n",
    "    output = self.decoder(output)\n",
    "    output = output.transpose(1, 0)\n",
    "    return output"
   ]
  },
  {
   "source": [
    "## Load Pretrained Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T10:45:22.803510Z",
     "iopub.status.busy": "2021-01-01T10:45:22.802863Z",
     "iopub.status.idle": "2021-01-01T10:45:28.623592Z",
     "shell.execute_reply": "2021-01-01T10:45:28.623052Z"
    },
    "papermill": {
     "duration": 5.839669,
     "end_time": "2021-01-01T10:45:28.623719",
     "exception": false,
     "start_time": "2021-01-01T10:45:22.784050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = '../input/saint-model/saint_model.pt'\n",
    "\n",
    "model = SAINT(ninp=100)\n",
    "device = \"cpu\" if not torch.cuda.is_available() else torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model.device = device\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device(device)))\n"
   ]
  },
  {
   "source": [
    "## Inference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T10:45:28.673395Z",
     "iopub.status.busy": "2021-01-01T10:45:28.669864Z",
     "iopub.status.idle": "2021-01-01T10:45:29.874383Z",
     "shell.execute_reply": "2021-01-01T10:45:29.873320Z"
    },
    "papermill": {
     "duration": 1.239065,
     "end_time": "2021-01-01T10:45:29.874509",
     "exception": false,
     "start_time": "2021-01-01T10:45:28.635444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 has a prediction as the following:            row_id  answered_correctly\n",
      "group_num                            \n",
      "0               0            0.378761\n",
      "0               1            0.817393\n",
      "0               2            0.840980\n",
      "0               3            0.762317\n",
      "0               4            0.354948\n",
      "0               5            0.477288\n",
      "0               6            0.630987\n",
      "0               7            0.775457\n",
      "0               8            0.678727\n",
      "0               9            0.653153\n",
      "0              10            0.692447\n",
      "0              11            0.364155\n",
      "0              12            0.364121\n",
      "0              13            0.372460\n",
      "0              14            0.377758\n",
      "0              15            0.735187\n",
      "0              16            0.605621\n",
      "0              17            0.874092\n",
      "Ran in 0.9022457599639893\n",
      "1 has a prediction as the following:            row_id  answered_correctly\n",
      "group_num                            \n",
      "1              18            0.649533\n",
      "1              19            0.479748\n",
      "1              20            0.487974\n",
      "1              21            0.490005\n",
      "1              22            0.411763\n",
      "1              23            0.901076\n",
      "1              24            0.897072\n",
      "1              25            0.910675\n",
      "1              26            0.706247\n",
      "1              27            0.680893\n",
      "1              28            0.683827\n",
      "1              29            0.681667\n",
      "1              30            0.826115\n",
      "1              31            0.799577\n",
      "1              32            0.830305\n",
      "1              33            0.819849\n",
      "1              34            0.445805\n",
      "1              35            0.522683\n",
      "1              37            0.399894\n",
      "1              38            0.772765\n",
      "1              39            0.628859\n",
      "1              40            0.442944\n",
      "1              41            0.266151\n",
      "1              42            0.248505\n",
      "1              43            0.244269\n",
      "1              44            0.317100\n",
      "1              45            0.431508\n",
      "Ran in 0.9156074523925781\n",
      "2 has a prediction as the following:            row_id  answered_correctly\n",
      "group_num                            \n",
      "2              46            0.390443\n",
      "2              47            0.581813\n",
      "2              48            0.432564\n",
      "2              49            0.557462\n",
      "2              50            0.414834\n",
      "2              51            0.828333\n",
      "2              53            0.565419\n",
      "2              54            0.434445\n",
      "2              55            0.342295\n",
      "2              56            0.685731\n",
      "2              57            0.650302\n",
      "2              58            0.681852\n",
      "2              59            0.661024\n",
      "2              60            0.716489\n",
      "2              61            0.410246\n",
      "2              62            0.890601\n",
      "2              63            0.573335\n",
      "2              64            0.524289\n",
      "2              65            0.494404\n",
      "2              66            0.665781\n",
      "2              67            0.640132\n",
      "2              69            0.472477\n",
      "2              70            0.641829\n",
      "2              71            0.778598\n",
      "2              72            0.747166\n",
      "2              73            0.619922\n",
      "Ran in 0.9303951263427734\n",
      "3 has a prediction as the following:            row_id  answered_correctly\n",
      "group_num                            \n",
      "3              74            0.268420\n",
      "3              75            0.655555\n",
      "3              76            0.879103\n",
      "3              77            0.892472\n",
      "3              78            0.867502\n",
      "3              79            0.887093\n",
      "3              80            0.902774\n",
      "3              81            0.657135\n",
      "3              82            0.387331\n",
      "3              84            0.792237\n",
      "3              86            0.640906\n",
      "3              87            0.896287\n",
      "3              88            0.874612\n",
      "3              89            0.880062\n",
      "3              90            0.766028\n",
      "3              91            0.675478\n",
      "3              92            0.818333\n",
      "3              93            0.828744\n",
      "3              94            0.828938\n",
      "3              95            0.449896\n",
      "3              96            0.435179\n",
      "3              97            0.434268\n",
      "3              98            0.847009\n",
      "3              99            0.743823\n",
      "3             100            0.603767\n",
      "3             101            0.555277\n",
      "3             102            0.721482\n",
      "3             103            0.664325\n",
      "3             104            0.673868\n",
      "3             105            0.684301\n",
      "3             106            0.579713\n",
      "3             107            0.590237\n",
      "3             108            0.871981\n",
      "Ran in 0.9435815811157227\n"
     ]
    }
   ],
   "source": [
    "dataset = Riiid(user_data, user_idx)\n",
    "start_time = time.time()\n",
    "\n",
    "def scale(X, x_min, x_max):\n",
    "    nom = (X-X.min(axis=0))*(x_max-x_min)\n",
    "    denom = X.max(axis=0) - X.min(axis=0)\n",
    "    denom[denom==0] = 1\n",
    "    return x_min + nom/denom \n",
    "\n",
    "for index, (test_df, sample_prediction_df) in enumerate(iter_test):\n",
    "    test_df = test_df[test_df.content_type_id == 0]\n",
    "\n",
    "    test_df[\"prior_question_elapsed_time\"].fillna(26000, inplace=True) # FIXME some random value fill in should it be like this?\n",
    "    test_df[\"prior_question_elapsed_time\"] = test_df[\"prior_question_elapsed_time\"] // 1000\n",
    "    test_df[\"prior_question_elapsed_time\"].clip(upper=300)\n",
    "    test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].astype(np.float16).fillna(-1).astype(np.int8)\n",
    "    test_df['part_id'] = np.array(list(map(lambda x: part_ids_map[x], test_df['content_id'])))\n",
    "\n",
    "    dataset.update(test_df)\n",
    "\n",
    "    preds = []\n",
    "    idxs = test_df['user_id']\n",
    "\n",
    "    batch = collate_fn([dataset[idx] for idx in idxs])\n",
    "    # print(batch)\n",
    "    content_id, task_id, part_id, prior_question_elapsed_time, mask, labels = batch\n",
    "    content_id = content_id.to(device)\n",
    "    task_id = task_id.to(device)\n",
    "    part_id = part_id.to(device)\n",
    "    prior_question_elapsed_time = prior_question_elapsed_time.to(device)\n",
    "    mask = mask.to(device)\n",
    "    labels = labels.to(device)\n",
    "    output = model.forward(content_id, part_id, prior_question_elapsed_time, mask)\n",
    "    # print(output)\n",
    "    #   output_prob = output[:,-1,1]\n",
    "    #   pred = (pred.cpu().numpy()).astype(np.int32)#[-1]  # we only care about the last one\n",
    "    preds = torch.sigmoid(output)[:,-1, 1].cpu().detach().numpy()\n",
    "\n",
    "    # Normalised [0,1]\n",
    "    sample_prediction_df['answered_correctly'] =  preds\n",
    "    print(f'{index} has a prediction as the following: {sample_prediction_df}')\n",
    "    env.predict(sample_prediction_df[['row_id', 'answered_correctly']])\n",
    "\n",
    "    print(f'Ran in {time.time() - start_time}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 48.880651,
   "end_time": "2021-01-01T10:45:31.329709",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-01T10:44:42.449058",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}