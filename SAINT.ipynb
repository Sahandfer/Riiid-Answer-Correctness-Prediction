{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import deque, defaultdict\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "source": [
    "## 1. Import datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants \n",
    "TRAIN_PATH = 'Data/riiid_train.pkl.gzip'\n",
    "\n",
    "AMOUNT = 100 # Number of questions per user\n",
    "PAD = 0 # Value for padding\n",
    "BATCH_SIZE = 100\n",
    "NUM_ENCODER = 4\n",
    "NUM_DECODER = 4\n",
    "MAX_SEQ = 100\n",
    "\n",
    "EMBED_DIMS = 32\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "TOTAL_EXE = 13523 # number of unique questions\n",
    "TOTAL_CAT = 10000\n",
    "\n",
    "DEVICE = 'cpu' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              row_id  timestamp     user_id  content_id  content_type_id  \\\n",
       "0                  0          0         115        5692            False   \n",
       "1                  1      56943         115        5716            False   \n",
       "2                  2     118363         115         128            False   \n",
       "3                  3     131167         115        7860            False   \n",
       "4                  4     137965         115        7922            False   \n",
       "...              ...        ...         ...         ...              ...   \n",
       "101230327  101230327  428564420  2147482888        3586            False   \n",
       "101230328  101230328  428585000  2147482888        6341            False   \n",
       "101230329  101230329  428613475  2147482888        4212            False   \n",
       "101230330  101230330  428649406  2147482888        6343            False   \n",
       "101230331  101230331  428692118  2147482888        7995            False   \n",
       "\n",
       "           task_container_id  user_answer  answered_correctly  \\\n",
       "0                          1            3                   1   \n",
       "1                          2            2                   1   \n",
       "2                          0            0                   1   \n",
       "3                          3            0                   1   \n",
       "4                          4            1                   1   \n",
       "...                      ...          ...                 ...   \n",
       "101230327                 22            0                   1   \n",
       "101230328                 23            3                   1   \n",
       "101230329                 24            3                   1   \n",
       "101230330                 25            1                   0   \n",
       "101230331                 26            3                   1   \n",
       "\n",
       "           prior_question_elapsed_time prior_question_had_explanation  \n",
       "0                                  NaN                           None  \n",
       "1                              37000.0                          False  \n",
       "2                              55000.0                          False  \n",
       "3                              19000.0                          False  \n",
       "4                              11000.0                          False  \n",
       "...                                ...                            ...  \n",
       "101230327                      18000.0                           True  \n",
       "101230328                      14000.0                           True  \n",
       "101230329                      14000.0                           True  \n",
       "101230330                      22000.0                           True  \n",
       "101230331                      29000.0                           True  \n",
       "\n",
       "[101230332 rows x 10 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>timestamp</th>\n      <th>user_id</th>\n      <th>content_id</th>\n      <th>content_type_id</th>\n      <th>task_container_id</th>\n      <th>user_answer</th>\n      <th>answered_correctly</th>\n      <th>prior_question_elapsed_time</th>\n      <th>prior_question_had_explanation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>115</td>\n      <td>5692</td>\n      <td>False</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>56943</td>\n      <td>115</td>\n      <td>5716</td>\n      <td>False</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>37000.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>118363</td>\n      <td>115</td>\n      <td>128</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>55000.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>131167</td>\n      <td>115</td>\n      <td>7860</td>\n      <td>False</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>19000.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>137965</td>\n      <td>115</td>\n      <td>7922</td>\n      <td>False</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>11000.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>101230327</th>\n      <td>101230327</td>\n      <td>428564420</td>\n      <td>2147482888</td>\n      <td>3586</td>\n      <td>False</td>\n      <td>22</td>\n      <td>0</td>\n      <td>1</td>\n      <td>18000.0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>101230328</th>\n      <td>101230328</td>\n      <td>428585000</td>\n      <td>2147482888</td>\n      <td>6341</td>\n      <td>False</td>\n      <td>23</td>\n      <td>3</td>\n      <td>1</td>\n      <td>14000.0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>101230329</th>\n      <td>101230329</td>\n      <td>428613475</td>\n      <td>2147482888</td>\n      <td>4212</td>\n      <td>False</td>\n      <td>24</td>\n      <td>3</td>\n      <td>1</td>\n      <td>14000.0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>101230330</th>\n      <td>101230330</td>\n      <td>428649406</td>\n      <td>2147482888</td>\n      <td>6343</td>\n      <td>False</td>\n      <td>25</td>\n      <td>1</td>\n      <td>0</td>\n      <td>22000.0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>101230331</th>\n      <td>101230331</td>\n      <td>428692118</td>\n      <td>2147482888</td>\n      <td>7995</td>\n      <td>False</td>\n      <td>26</td>\n      <td>3</td>\n      <td>1</td>\n      <td>29000.0</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>101230332 rows Ã— 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "train_df = pd.read_pickle(TRAIN_PATH)\n",
    "train_df"
   ]
  },
  {
   "source": [
    "## 2. Data Pre-Processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove lectures\n",
    "train_df = train_df[train_df.content_type_id == 0]\n",
    "\n",
    "# Find unique skills\n",
    "skills = train_df[\"content_id\"].unique()\n",
    "n_skill = len(skills)\n",
    "\n",
    "\"\"\"\n",
    "1. Fill NA elapsed time\n",
    "2. Change unit to seconds\n",
    "3. Crop out the top 300 elapsed times\n",
    "\"\"\"\n",
    "train_df.prior_question_elapsed_time.fillna(0, inplace=True)\n",
    "train_df.prior_question_elapsed_time /= 1000\n",
    "train_df.prior_question_elapsed_time = train_df.prior_question_elapsed_time.astype(np.int)\n",
    "# df_train.prior_question_elapsed_time.clip(upper=300)\n",
    "\n",
    "# Group by user\n",
    "user_df = train_df[[\"user_id\", \"content_id\", \"answered_correctly\", \"prior_question_elapsed_time\", \"task_container_id\"]].groupby('user_id').apply(lambda r: (\n",
    "            r.content_id.values,\n",
    "            r.answered_correctly.values,\n",
    "            r.prior_question_elapsed_time.values, \n",
    "            r.task_container_id.values\n",
    "            ))\n",
    "\n",
    "del train_df\n",
    "gc.collect()\n",
    "\n",
    "import pickle\n",
    "with open('user_df.pickle', 'wb') as f:\n",
    "  pickle.dump(user_df,f)"
   ]
  },
  {
   "source": [
    "## 3. Creating the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiiidDataset(Dataset):\n",
    "    def __init__(self, user_df, max_seq=100):\n",
    "        super(RiiidDataset, self).__init__()\n",
    "        self.user_df = user_df\n",
    "        self.max_seq = max_seq\n",
    "        self.user_ids = []\n",
    "\n",
    "        for user_id in self.user_df.index:\n",
    "            exercise_id, answered_correctly, elapsed_time, container_id = self.user_df[user_id]\n",
    "            # Remove users who did less than 10 exercises\n",
    "            ex_num = len(exercise_id) # number of exercises\n",
    "            if ex_num >= 10:\n",
    "                self.user_ids.append(user_id)\n",
    "                # idx = min(ex_num, max_seq)\n",
    "                # entry = (exercise_id[:idx], answered_correctly[:idx],elapsed_time[:idx], container_id[:idx])\n",
    "                # self.dataset.append(entry)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_id = self.user_ids[idx]\n",
    "        exercise_id, answered_correctly, elapsed_time, container_id = self.user_df[user_id]\n",
    "\n",
    "        ex_num = len(exercise_id)\n",
    "\n",
    "        exercise_id_temp = np.zeros(self.max_seq, dtype=int)\n",
    "        answered_correctly_temp = np.zeros(self.max_seq, dtype=int)\n",
    "        elapsed_time_temp = np.zeros(self.max_seq, dtype=int)\n",
    "        container_id_temp = np.zeros(self.max_seq, dtype=int)\n",
    "\n",
    "        if ex_num >= self.max_seq:\n",
    "            exercise_id_temp= exercise_id[-self.max_seq:]\n",
    "            answered_correctly_temp = answered_correctly[-self.max_seq:]\n",
    "            elapsed_time_temp = elapsed_time[-self.max_seq:]\n",
    "            container_id_temp= container_id[-self.max_seq:]\n",
    "        else:\n",
    "            exercise_id_temp[-ex_num:] = exercise_id\n",
    "            answered_correctly_temp[-ex_num:] = answered_correctly\n",
    "            elapsed_time_temp[-ex_num:] = elapsed_time\n",
    "            container_id_temp[-ex_num:] = container_id\n",
    "\n",
    "        return exercise_id_temp, answered_correctly_temp, elapsed_time_temp, container_id_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "388"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "train, val = train_test_split(user_df, test_size=0.2)\n",
    "\n",
    "train_dataset = RiiidDataset(train, max_seq=MAX_SEQ)\n",
    "val_dataset = RiiidDataset(val, max_seq=MAX_SEQ)\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            num_workers=8,\n",
    "                            shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        num_workers=8,\n",
    "                        shuffle=True)\n",
    "del train, val, train_dataset, val_dataset\n",
    "gc.collect()"
   ]
  },
  {
   "source": [
    "## 4. Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed Forward Layer\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(FFN, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features, in_features)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(in_features, in_features)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return self.dropout(x)\n",
    "\"\"\"\n",
    "        SAINT+ Model has 3 input embeddings for the encoder part\":\n",
    "        1. Exercise ID\n",
    "        2. Position\n",
    "        3. Part (10000 unique task container id)\n",
    "\"\"\"\n",
    "class EncoderEmbedding(nn.Module):\n",
    "    def __init__(self, n_exercises, n_categories, n_dims, seq_len):\n",
    "        super(EncoderEmbedding, self).__init__()\n",
    "        self.n_dims = n_dims\n",
    "        self.seq_len = seq_len\n",
    "        self.exercise_embedding = nn.Embedding(n_exercises, n_dims)\n",
    "        self.position_embediing = nn.Embedding(seq_len, n_dims)\n",
    "        self.part_embedding = nn.Embedding(n_categories, n_dims)\n",
    "\n",
    "    def forward(self, exercises, categories):\n",
    "        e = self.exercise_embedding(exercises)\n",
    "        c = self.part_embedding(categories)\n",
    "        seq = torch.arange(self.seq_len, device=device).unsqueeze(0)\n",
    "        p = self.position_embediing(seq)\n",
    "        return p + c + e\n",
    "\n",
    "\"\"\"\n",
    "        SAINT+ Model has 4 input embeddings for the decoder part\":\n",
    "        1. Correctness (response)\n",
    "        2. Position\n",
    "        3. Elapsed Time\n",
    "        4. Lag Time (to be implemented)\n",
    "\"\"\"\n",
    "class DecoderEmbedding(nn.Module):\n",
    "    def __init__(self, n_responses, n_dims, seq_len):\n",
    "        super(DecoderEmbedding, self).__init__()\n",
    "        self.n_dims = n_dims\n",
    "        self.seq_len = seq_len\n",
    "        self.response_embedding = nn.Embedding(n_responses, n_dims)\n",
    "        self.elapsed_time_embedding = nn.Linear(1,n_dims,bias=False)\n",
    "        self.position_embedding = nn.Embedding(seq_len, n_dims)\n",
    "\n",
    "    def forward(self, responses, elapsed_times):\n",
    "        e = self.response_embedding(responses)\n",
    "        # t = self.elapsed_time_embedding(elapsed_times)\n",
    "        seq = torch.arange(self.seq_len, device=device).unsqueeze(0)\n",
    "        p = self.position_embedding(seq)\n",
    "        return p + e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAINT(nn.Module):\n",
    "    def __init__(self, n_skill, max_seq=MAX_SEQ, embed_dim=EMBED_DIMS):\n",
    "        super(SAINT, self).__init__()\n",
    "        self.n_skill = n_skill\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.encoder_embedding = EncoderEmbedding(n_skill, 10000, embed_dim, max_seq)\n",
    "        self.decoder_embedding = DecoderEmbedding(n_skill, embed_dim, max_seq)\n",
    "\n",
    "        # self.encoder_layer = StackedNMultiHeadAttention(n_stacks=NUM_DECODER,n_dims=EMBED_DIMS,n_heads=DEC_HEADS,seq_len=MAX_SEQ,n_multihead=1,dropout=0.2)\n",
    "        # self.decoder_layer = StackedNMultiHeadAttention(n_stacks=NUM_ENCODER,n_dims=EMBED_DIMS, n_heads=ENC_HEADS,seq_len=MAX_SEQ,n_multihead=2,dropout=0.2)\n",
    "        self.encoder_layer = nn.MultiheadAttention(embed_dim, num_heads=ENC_HEADS, dropout=0.2)\n",
    "        self.decoder_layer = nn.MultiheadAttention(embed_dim, num_heads=DEC_HEADS, dropout=0.2)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.layer_normal = nn.LayerNorm(embed_dim) \n",
    "\n",
    "        self.ffn = FFN(embed_dim)\n",
    "        self.pred = nn.Linear(embed_dim, 1)\n",
    "\n",
    "    def future_mask(self, seq_length):\n",
    "        future_mask = np.triu(np.ones((seq_length, seq_length)), k=1).astype('bool')\n",
    "        return torch.from_numpy(future_mask)\n",
    "    \n",
    "    def forward(self, exercise_id, label, elapsed_time, container_id):\n",
    "        enc_emb = self.encoder_embedding(exercise_id, container_id)\n",
    "\n",
    "        self.elapsed_time = nn.Linear(1,EMBED_DIMS)\n",
    "        elapsed_time=elapsed_time.unsqueeze(-1).float()\n",
    "        ela_time = self.elapsed_time(elapsed_time)\n",
    "        \n",
    "        dec_emb = self.decoder_embedding(label, elapsed_time)\n",
    "        dec_emb = dec_emb + ela_time\n",
    "\n",
    "        attn_mask = self.future_mask(len(exercise_id)).to(device)\n",
    "        \n",
    "        enc_output, enc_weights = self.encoder_layer(enc_emb, enc_emb, enc_emb, attn_mask =attn_mask)\n",
    "        enc_output = enc_output.permute(1,0,2)\n",
    "        dec_output, dec_weights = self.decoder_layer(enc_output, dec_emb, dec_emb)\n",
    "        # dec_output = self.ffn(dec_output)\n",
    "\n",
    "        output = self.pred(dec_output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SAINT(\n",
       "  (encoder_embedding): EncoderEmbedding(\n",
       "    (exercise_embedding): Embedding(13523, 32)\n",
       "    (position_embediing): Embedding(100, 32)\n",
       "    (part_embedding): Embedding(10000, 32)\n",
       "  )\n",
       "  (decoder_embedding): DecoderEmbedding(\n",
       "    (response_embedding): Embedding(13523, 32)\n",
       "    (elapsed_time_embedding): Linear(in_features=1, out_features=32, bias=False)\n",
       "    (position_embedding): Embedding(100, 32)\n",
       "  )\n",
       "  (encoder_layer): MultiheadAttention(\n",
       "    (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (decoder_layer): MultiheadAttention(\n",
       "    (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (layer_normal): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  (ffn): FFN(\n",
       "    (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (pred): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "model = SAINT(n_skill)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.99, weight_decay=0.005)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_iterator, optim,  criterion, device=\"cpu\"):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = []\n",
    "    num_corrects = 0\n",
    "    num_total = 0\n",
    "    labels = []\n",
    "    outs = []\n",
    "\n",
    "    tbar = tqdm(train_iterator)\n",
    "    for item in tbar:\n",
    "        exercise_ids = item[0].to(device).long()\n",
    "        label = item[1].to(device).long()\n",
    "        elapsed_times = item[2].to(device).long()\n",
    "        container_ids= item[3].to(device).long()\n",
    "\n",
    "        target_mask = (exercise_ids != 0)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        output = model(exercise_ids, label, elapsed_times, container_ids)\n",
    "        \n",
    "        outputs = torch.masked_select(output.permute(1,0,2)[:,-1], target_mask)\n",
    "        label = torch.masked_select(label, target_mask)\n",
    "        \n",
    "        loss = criterion(outputs.float(), label.float())\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        train_loss.append(loss.item())\n",
    "        pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "        \n",
    "        num_corrects += (pred == label).sum().item()\n",
    "        num_total += len(label)\n",
    "\n",
    "        labels.extend(label.view(-1).data.cpu().numpy())\n",
    "        outs.extend(outputs.view(-1).data.cpu().numpy())\n",
    "\n",
    "        tbar.set_description('loss - {:.4f}'.format(loss))\n",
    "\n",
    "    acc = num_corrects / num_total\n",
    "    auc = roc_auc_score(labels, outs)\n",
    "    loss = np.average(train_loss)\n",
    "    return loss, acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epoch(model, val_iterator, criterion, device=\"cpu\"):\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = []\n",
    "    num_corrects = 0\n",
    "    num_total = 0\n",
    "    labels = []\n",
    "    outs = []\n",
    "\n",
    "    tbar = tqdm(val_iterator)\n",
    "    for item in tbar:\n",
    "        exercise_ids = item[0].to(device).long()\n",
    "        label = item[1].to(device).long()\n",
    "        elapsed_times = item[2].to(device).long()\n",
    "        container_ids= item[3].to(device).long()\n",
    "\n",
    "        target_mask = (exercise_ids != 0)\n",
    "\n",
    "        output = model(exercise_ids, label, elapsed_times, container_ids)\n",
    "        \n",
    "        outputs = torch.masked_select(output.permute(1,0,2)[:,-1], target_mask)\n",
    "        label = torch.masked_select(label, target_mask)\n",
    "\n",
    "        loss = criterion(outputs.float(), label.float())\n",
    "        loss.backward()\n",
    "        val_loss.append(loss.item())\n",
    "        pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "        \n",
    "        num_corrects += (pred == label).sum().item()\n",
    "        num_total += len(label)\n",
    "\n",
    "        labels.extend(label.view(-1).data.cpu().numpy())\n",
    "        outs.extend(outputs.view(-1).data.cpu().numpy())\n",
    "\n",
    "        tbar.set_description('loss - {:.4f}'.format(loss))\n",
    "\n",
    "    acc = num_corrects / num_total\n",
    "    auc = roc_auc_score(labels, outs)\n",
    "    loss = np.average(val_loss)\n",
    "    return loss, acc, auc"
   ]
  },
  {
   "source": [
    "## 5. Inferencing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3129.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99c99434edca49fb94cf7a806ab6c419"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "epoch - 0 train_loss - 0.68 acc - 5905.603 auc - 0.500\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=782.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be16d920f2c54bf38b6b0c151ec93d88"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "epoch - 0 val_loss - 0.68 acc - 5905.434 auc - 0.500\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3129.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b9f5fa0e728b44848569250dbcd6beb8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "epoch - 1 train_loss - 0.68 acc - 5910.787 auc - 0.501\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=782.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c9dacd8a95242f08341ce7d86030861"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-049dde4ac68e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch - {} train_loss - {:.2f} acc - {:.3f} auc - {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavl_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch - {} val_loss - {:.2f} acc - {:.3f} auc - {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavl_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-a0c77dce5c95>\u001b[0m in \u001b[0;36mval_epoch\u001b[0;34m(model, val_iterator, criterion, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "over_fit = 0\n",
    "last_auc = 0\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc, train_auc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    print(\"epoch - {} train_loss - {:.2f} acc - {:.3f} auc - {:.3f}\".format(epoch, train_loss, train_acc, train_auc))\n",
    "    \n",
    "    val_loss, avl_acc, val_auc = val_epoch(model, val_loader, criterion, device)\n",
    "    print(\"epoch - {} val_loss - {:.2f} acc - {:.3f} auc - {:.3f}\".format(epoch, val_loss, avl_acc, val_auc))\n",
    "    \n",
    "    if val_auc > last_auc:\n",
    "        last_auc = val_auc\n",
    "        over_fit = 0\n",
    "    else:\n",
    "        over_fit += 1\n",
    "        \n",
    "    \n",
    "    if over_fit >= 2:\n",
    "        print(\"early stop epoch \", epoch)\n",
    "        break"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}