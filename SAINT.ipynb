{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import deque, defaultdict\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "source": [
    "## 1. Import datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants \n",
    "TRAIN_PATH = 'Data/riiid_train.pkl.gzip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMOUNT = 100 # Number of questions per user\n",
    "PAD = 0 # Value for padding\n",
    "BATCH_SIZE = 100\n",
    "NUM_ENCODER = 4\n",
    "NUM_DECODER = 4\n",
    "MAX_SEQ = 100\n",
    "\n",
    "EMBED_DIMS = 32\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "TOTAL_EXE = 13523 # number of unique questions\n",
    "TOTAL_CAT = 10000\n",
    "\n",
    "DEVICE = 'cpu' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 101230332 entries, 0 to 101230331\nData columns (total 10 columns):\n #   Column                          Dtype  \n---  ------                          -----  \n 0   row_id                          int64  \n 1   timestamp                       int64  \n 2   user_id                         int32  \n 3   content_id                      int16  \n 4   content_type_id                 bool   \n 5   task_container_id               int16  \n 6   user_answer                     int8   \n 7   answered_correctly              int8   \n 8   prior_question_elapsed_time     float32\n 9   prior_question_had_explanation  object \ndtypes: bool(1), float32(1), int16(2), int32(1), int64(2), int8(2), object(1)\nmemory usage: 3.7+ GB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_pickle(TRAIN_PATH)\n",
    "train_df.info()"
   ]
  },
  {
   "source": [
    "## 2. Data Pre-Processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Remove lectures\n",
    "train_df = train_df[train_df.content_type_id == 0]\n",
    "\n",
    "# Find unique skills\n",
    "skills = train_df[\"content_id\"].unique()\n",
    "n_skill = len(skills)\n",
    "\n",
    "\"\"\"\n",
    "1. Fill NA elapsed time\n",
    "2. Change unit to seconds\n",
    "3. Crop out the top 300 elapsed times\n",
    "\"\"\"\n",
    "train_df.prior_question_elapsed_time.fillna(0, inplace=True)\n",
    "train_df.prior_question_elapsed_time /= 1000\n",
    "train_df.prior_question_elapsed_time = train_df.prior_question_elapsed_time.astype(np.int)\n",
    "# df_train.prior_question_elapsed_time.clip(upper=300)\n",
    "\n",
    "# Group by user\n",
    "user_df = train_df[[\"user_id\", \"content_id\", \"answered_correctly\", \"prior_question_elapsed_time\", \"task_container_id\"]].groupby('user_id').apply(lambda r: (\n",
    "            r.content_id.values,\n",
    "            r.answered_correctly.values,\n",
    "            r.prior_question_elapsed_time.values, \n",
    "            r.task_container_id.values\n",
    "            ))\n",
    "\n",
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "source": [
    "## 3. Creating the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiiidDataset(Dataset):\n",
    "    def __init__(self, user_df, max_seq=100):\n",
    "        super(RiiidDataset, self).__init__()\n",
    "        self.user_df = user_df\n",
    "        self.max_seq = max_seq\n",
    "        self.user_ids = []\n",
    "\n",
    "        for user_id in self.user_df.index:\n",
    "            exercise_id, answered_correctly, elapsed_time, container_id = self.user_df[user_id]\n",
    "            # Remove users who did less than 10 exercises\n",
    "            ex_num = len(exercise_id) # number of exercises\n",
    "            if ex_num >= 10:\n",
    "                self.user_ids.append(user_id)\n",
    "                # idx = min(ex_num, max_seq)\n",
    "                # entry = (exercise_id[:idx], answered_correctly[:idx],elapsed_time[:idx], container_id[:idx])\n",
    "                # self.dataset.append(entry)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_id = self.user_ids[idx]\n",
    "        exercise_id, answered_correctly, elapsed_time, container_id = self.user_df[user_id]\n",
    "\n",
    "        ex_num = len(exercise_id)\n",
    "\n",
    "        exercise_id_temp = np.zeros(self.max_seq, dtype=int)\n",
    "        answered_correctly_temp = np.zeros(self.max_seq, dtype=int)\n",
    "        elapsed_time_temp = np.zeros(self.max_seq, dtype=int)\n",
    "        container_id_temp = np.zeros(self.max_seq, dtype=int)\n",
    "\n",
    "        if ex_num >= self.max_seq:\n",
    "            exercise_id_temp[:] = exercise_id[-self.max_seq:]\n",
    "            answered_correctly_temp[:] = answered_correctly[-self.max_seq:]\n",
    "            elapsed_time_temp[:] = elapsed_time[-self.max_seq:]\n",
    "            container_id_temp[:] = container_id[-self.max_seq:]\n",
    "        else:\n",
    "            exercise_id_temp[-ex_num:] = exercise_id\n",
    "            answered_correctly_temp[-ex_num:] = answered_correctly\n",
    "            elapsed_time_temp[-ex_num:] = elapsed_time\n",
    "            container_id_temp[-ex_num:] = container_id\n",
    "\n",
    "        exercise_ids = exercise_id_temp\n",
    "        labels = answered_correctly_temp\n",
    "        elapsed_times = elapsed_time_temp\n",
    "        container_ids = container_id_temp\n",
    "\n",
    "        return exercise_id_temp, answered_correctly_temp, answered_correctly_temp, container_id_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train, val = train_test_split(user_df, test_size=0.2)\n",
    "\n",
    "train_dataset = RiiidDataset(train, max_seq=MAX_SEQ)\n",
    "val_dataset = RiiidDataset(val, max_seq=MAX_SEQ)\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            num_workers=8,\n",
    "                            shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        num_workers=8,\n",
    "                        shuffle=True)\n",
    "del train, val, train_dataset, val_dataset\n",
    "gc.collect()"
   ]
  },
  {
   "source": [
    "## 4. Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed Forward Layer\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(FFN, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features, in_features)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(in_features, in_features)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        SAINT+ Model has 3 input embeddings for the encoder part\":\n",
    "        1. Exercise ID\n",
    "        2. Position\n",
    "        3. Part (10000 unique task container id)\n",
    "\"\"\"\n",
    "class EncoderEmbedding(nn.Module):\n",
    "    def __init__(self, n_exercises, n_categories, n_dims, seq_len):\n",
    "        super(EncoderEmbedding, self).__init__()\n",
    "        self.n_dims = n_dims\n",
    "        self.seq_len = seq_len\n",
    "        self.exercise_embedding = nn.Embedding(n_exercises, n_dims)\n",
    "        self.position_embediing = nn.Embedding(seq_len, n_dims)\n",
    "        self.part_embedding = nn.Embedding(n_categories, n_dims)\n",
    "\n",
    "    def forward(self, exercises, categories):\n",
    "        e = self.exercise_embedding(exercises)\n",
    "        c = self.part_embedding(categories)\n",
    "        seq = torch.arange(self.seq_len, device=device).unsqueeze(0)\n",
    "        p = self.position_embediing(seq)\n",
    "        return p + c + e\n",
    "\n",
    "\"\"\"\n",
    "        SAINT+ Model has 4 input embeddings for the decoder part\":\n",
    "        1. Correctness (response)\n",
    "        2. Position\n",
    "        3. Elapsed Time\n",
    "        4. Lag Time (to be implemented)\n",
    "\"\"\"\n",
    "class DecoderEmbedding(nn.Module):\n",
    "    def __init__(self, n_responses, n_dims, seq_len):\n",
    "        super(DecoderEmbedding, self).__init__()\n",
    "        self.n_dims = n_dims\n",
    "        self.seq_len = seq_len\n",
    "        self.response_embedding = nn.Embedding(n_responses, n_dims)\n",
    "        self.elapsed_time_embedding = nn.Embedding(300, n_dims)\n",
    "        self.position_embedding = nn.Embedding(seq_len, n_dims)\n",
    "\n",
    "    def forward(self, responses, elapsed_times):\n",
    "        e = self.response_embedding(responses)\n",
    "        t = self.elapsed_time_embedding(elapsed_times)\n",
    "        seq = torch.arange(self.seq_len, device=device).unsqueeze(0)\n",
    "        p = self.position_embedding(seq)\n",
    "        return p + e + t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *Copied*\n",
    "class StackedNMultiHeadAttention(nn.Module):\n",
    "  def __init__(self,n_stacks,n_dims,n_heads,seq_len,n_multihead=1,dropout=0.2):\n",
    "    super(StackedNMultiHeadAttention,self).__init__()\n",
    "    self.n_stacks = n_stacks\n",
    "    self.n_multihead = n_multihead\n",
    "    self.n_dims = n_dims \n",
    "    self.norm_layers = nn.LayerNorm(n_dims)\n",
    "    #n_stacks has n_multiheads each\n",
    "    self.multihead_layers = nn.ModuleList(n_stacks*[nn.ModuleList(n_multihead*[nn.MultiheadAttention(embed_dim = n_dims,\n",
    "                                                      num_heads = n_heads,\n",
    "                                                        dropout = dropout),]),])\n",
    "    self.ffn = nn.ModuleList(n_stacks*[FFN(n_dims)])\n",
    "    self.mask = torch.triu(torch.ones(seq_len,seq_len),diagonal=1).to(dtype=torch.bool)\n",
    "  \n",
    "  def forward(self,input_q,input_k,input_v,encoder_output=None,break_layer=None):\n",
    "    for stack in range(self.n_stacks):\n",
    "        for multihead in range(self.n_multihead):\n",
    "          norm_q = self.norm_layers(input_q)\n",
    "          norm_k = self.norm_layers(input_k)\n",
    "          norm_v = self.norm_layers(input_v) \n",
    "          heads_output,_ = self.multihead_layers[stack][multihead](query=norm_q.permute(1,0,2),\n",
    "                                                                    key=norm_k.permute(1,0,2),\n",
    "                                                                    value=norm_v.permute(1,0,2),\n",
    "                                                                    attn_mask=self.mask.to(device))\n",
    "          heads_output = heads_output.permute(1,0,2)\n",
    "          #assert encoder_output != None and break_layer is not None     \n",
    "          if encoder_output != None and multihead == break_layer:\n",
    "            assert break_layer <= multihead, \" break layer should be less than multihead layers and postive integer\"\n",
    "            input_k = input_v = encoder_output\n",
    "            input_q =input_q + heads_output\n",
    "          else:\n",
    "            input_q =input_q+ heads_output\n",
    "            input_k =input_k+ heads_output\n",
    "            input_v =input_v +heads_output\n",
    "        last_norm = self.norm_layers(heads_output)\n",
    "        ffn_output = self.ffn[stack](last_norm)\n",
    "        ffn_output =ffn_output+ heads_output\n",
    "    return ffn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAINT(nn.Module):\n",
    "    def __init__(self, n_skill, max_seq=MAX_SEQ, embed_dim=EMBED_DIMS):\n",
    "        super(SAINT, self).__init__()\n",
    "        self.n_skill = n_skill\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.encoder_embedding = EncoderEmbedding(n_skill, 10000, embed_dim, max_seq)\n",
    "        self.decoder_embedding = DecoderEmbedding(n_skill, embed_dim, max_seq)\n",
    "\n",
    "        # self.encoder_layer = StackedNMultiHeadAttention(n_stacks=NUM_DECODER,n_dims=EMBED_DIMS,n_heads=DEC_HEADS,seq_len=MAX_SEQ,n_multihead=1,dropout=0.2)\n",
    "        # self.decoder_layer = StackedNMultiHeadAttention(n_stacks=NUM_ENCODER,n_dims=EMBED_DIMS, n_heads=ENC_HEADS,seq_len=MAX_SEQ,n_multihead=2,dropout=0.2)\n",
    "        self.encoder_layer = nn.MultiheadAttention(embed_dim, num_heads=ENC_HEADS, dropout=0.2)\n",
    "        self.decoder_layer = nn.MultiheadAttention(embed_dim, num_heads=DEC_HEADS, dropout=0.2)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.layer_normal = nn.LayerNorm(embed_dim) \n",
    "\n",
    "        self.ffn = FFN(embed_dim)\n",
    "        self.pred = nn.Linear(embed_dim, 1)\n",
    "\n",
    "    def future_mask(self, seq_length):\n",
    "        future_mask = np.triu(np.ones((seq_length, seq_length)), k=1).astype('bool')\n",
    "        return torch.from_numpy(future_mask)\n",
    "    \n",
    "    def forward(self, exercise_id, label, elapsed_time, container_id):\n",
    "        enc_emb = self.encoder_embedding(exercise_id, container_id)\n",
    "        dec_emb = self.decoder_embedding(label, elapsed_time)\n",
    "\n",
    "        attn_mask = self.future_mask(len(exercise_id)).to(device)\n",
    "        \n",
    "        enc_output, enc_weights = self.encoder_layer(enc_emb, enc_emb, enc_emb, attn_mask =attn_mask)\n",
    "        enc_output = enc_output.permute(1,0,2)\n",
    "        dec_output, dec_weights = self.decoder_layer(enc_output, dec_emb, dec_emb)\n",
    "        # dec_output = self.ffn(dec_output)\n",
    "\n",
    "        output = self.pred(dec_output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SAINT(\n",
       "  (encoder_embedding): EncoderEmbedding(\n",
       "    (exercise_embedding): Embedding(13523, 32)\n",
       "    (position_embediing): Embedding(100, 32)\n",
       "    (part_embedding): Embedding(10000, 32)\n",
       "  )\n",
       "  (decoder_embedding): DecoderEmbedding(\n",
       "    (response_embedding): Embedding(13523, 32)\n",
       "    (elapsed_time_embedding): Embedding(300, 32)\n",
       "    (position_embedding): Embedding(100, 32)\n",
       "  )\n",
       "  (encoder_layer): MultiheadAttention(\n",
       "    (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (decoder_layer): MultiheadAttention(\n",
       "    (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (layer_normal): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  (ffn): FFN(\n",
       "    (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (pred): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "model = SAINT(n_skill)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.99, weight_decay=0.005)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, val_iterator, optim,  criterion, device=\"cpu\"):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = []\n",
    "    num_corrects = 0\n",
    "    num_total = 0\n",
    "    labels = []\n",
    "    outs = []\n",
    "\n",
    "    tbar = tqdm(train_iterator)\n",
    "    for item in tbar:\n",
    "        exercise_ids = item[0].to(device).long()\n",
    "        label = item[1].to(device).long()\n",
    "        elapsed_times = item[2].to(device).long()\n",
    "        container_ids= item[3].to(device).long()\n",
    "\n",
    "        target_mask = (exercise_ids != 0)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        output = model(exercise_ids, label, elapsed_times, container_ids)\n",
    "        \n",
    "        outputs = torch.masked_select(output.permute(1,0,2)[:,-1], target_mask)\n",
    "        label = torch.masked_select(label, target_mask)\n",
    "        \n",
    "        loss = criterion(outputs.float(), label.float())\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        train_loss.append(loss.item())\n",
    "        pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "        \n",
    "        num_corrects += (pred == label).sum().item()\n",
    "        num_total += len(label)\n",
    "\n",
    "        labels.extend(label.view(-1).data.cpu().numpy())\n",
    "        outs.extend(outputs.view(-1).data.cpu().numpy())\n",
    "\n",
    "        tbar.set_description('loss - {:.4f}'.format(loss))\n",
    "\n",
    "    acc = num_corrects / num_total\n",
    "    auc = roc_auc_score(labels, outs)\n",
    "    loss = np.average(train_loss)\n",
    "    return loss, acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epoch(model, val_iterator, criterion, device=\"cpu\"):\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = []\n",
    "    num_corrects = 0\n",
    "    num_total = 0\n",
    "    labels = []\n",
    "    outs = []\n",
    "\n",
    "    tbar = tqdm(val_iterator)\n",
    "    for item in tbar:\n",
    "        exercise_ids = item[0].to(device).long()\n",
    "        label = item[1].to(device).long()\n",
    "        elapsed_times = item[2].to(device).long()\n",
    "        container_ids= item[3].to(device).long()\n",
    "\n",
    "        target_mask = (exercise_ids != 0)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        output = model(exercise_ids, label, elapsed_times, container_ids)\n",
    "        \n",
    "        outputs = torch.masked_select(output.permute(1,0,2)[:,-1], target_mask)\n",
    "        label = torch.masked_select(label, target_mask)\n",
    "\n",
    "        loss = criterion(outputs.float(), label.float())\n",
    "        loss.backward()\n",
    "        val_loss.append(loss.item())\n",
    "        pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "        \n",
    "        num_corrects += (pred == label).sum().item()\n",
    "        num_total += len(label)\n",
    "\n",
    "        labels.extend(label.view(-1).data.cpu().numpy())\n",
    "        outs.extend(outputs.view(-1).data.cpu().numpy())\n",
    "\n",
    "        tbar.set_description('loss - {:.4f}'.format(loss))\n",
    "\n",
    "    acc = num_corrects / num_total\n",
    "    auc = roc_auc_score(labels, outs)\n",
    "    loss = np.average(val_loss)\n",
    "    return loss, acc, auc"
   ]
  },
  {
   "source": [
    "## 5. Inferencing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "train_epoch() takes from 3 to 4 positional arguments but 5 were given",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-049dde4ac68e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlast_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch - {} train_loss - {:.2f} acc - {:.3f} auc - {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: train_epoch() takes from 3 to 4 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "over_fit = 0\n",
    "last_auc = 0\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc, train_auc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    print(\"epoch - {} train_loss - {:.2f} acc - {:.3f} auc - {:.3f}\".format(epoch, train_loss, train_acc, train_auc))\n",
    "    \n",
    "    val_loss, avl_acc, val_auc = val_epoch(model, val_loader, criterion, device)\n",
    "    print(\"epoch - {} val_loss - {:.2f} acc - {:.3f} auc - {:.3f}\".format(epoch, val_loss, avl_acc, val_auc))\n",
    "    \n",
    "    if val_auc > last_auc:\n",
    "        last_auc = val_auc\n",
    "        over_fit = 0\n",
    "    else:\n",
    "        over_fit += 1\n",
    "        \n",
    "    \n",
    "    if over_fit >= 2:\n",
    "        print(\"early stop epoch \", epoch)\n",
    "        break"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}